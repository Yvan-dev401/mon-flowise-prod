{
  "nodes": [
    {
      "id": "recursiveCharacterTextSplitter_0",
      "position": {
        "x": 164.48228006768284,
        "y": 346.55475290099275
      },
      "type": "customNode",
      "data": {
        "id": "recursiveCharacterTextSplitter_0",
        "label": "Recursive Character Text Splitter",
        "version": 2,
        "name": "recursiveCharacterTextSplitter",
        "type": "RecursiveCharacterTextSplitter",
        "baseClasses": [
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "description": "Number of characters in each chunk. Default is 1000.",
            "default": 1000,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkSize-number",
            "display": true
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "description": "Number of characters to overlap between chunks. Default is 200.",
            "default": 200,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-chunkOverlap-number",
            "display": true
          },
          {
            "label": "Custom Separators",
            "name": "separators",
            "type": "string",
            "rows": 4,
            "description": "Array of custom separators to determine when to split the text, will override the default separators",
            "placeholder": "[\"|\", \"##\", \">\", \"-\"]",
            "additionalParams": true,
            "optional": true,
            "id": "recursiveCharacterTextSplitter_0-input-separators-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": 200,
          "separators": ""
        },
        "outputAnchors": [
          {
            "id": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "recursiveCharacterTextSplitter",
            "label": "RecursiveCharacterTextSplitter",
            "description": "Split documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \"",
            "type": "RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 436,
      "positionAbsolute": {
        "x": 164.48228006768284,
        "y": 346.55475290099275
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "pinecone_0",
      "position": {
        "x": 1548.5940742991306,
        "y": 277.9050270774794
      },
      "type": "customNode",
      "data": {
        "id": "pinecone_0",
        "label": "Pinecone",
        "version": 5,
        "name": "pinecone",
        "type": "Pinecone",
        "baseClasses": [
          "Pinecone",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity or mmr search using Pinecone, a leading fully managed hosted vector database",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "pineconeApi"
            ],
            "id": "pinecone_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Pinecone Index",
            "name": "pineconeIndex",
            "type": "string",
            "id": "pinecone_0-input-pineconeIndex-string",
            "display": true
          },
          {
            "label": "Pinecone Namespace",
            "name": "pineconeNamespace",
            "type": "string",
            "placeholder": "my-first-namespace",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeNamespace-string",
            "display": true
          },
          {
            "label": "File Upload",
            "name": "fileUpload",
            "description": "Allow file upload on the chat",
            "hint": {
              "label": "How to use",
              "value": "\n**File Upload**\n\nThis allows file upload on the chat. Uploaded files will be upserted on the fly to the vector store.\n\n**Note:**\n- You can only turn on file upload for one vector store at a time.\n- At least one Document Loader node should be connected to the document input.\n- Document Loader should be file types like PDF, DOCX, TXT, etc.\n\n**How it works**\n- Uploaded files will have the metadata updated with the chatId.\n- This will allow the file to be associated with the chatId.\n- When querying, metadata will be filtered by chatId to retrieve files associated with the chatId.\n"
            },
            "type": "boolean",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fileUpload-boolean",
            "display": true
          },
          {
            "label": "Pinecone Text Key",
            "name": "pineconeTextKey",
            "description": "The key in the metadata for storing text. Default to `text`",
            "type": "string",
            "placeholder": "text",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-pineconeTextKey-string",
            "display": true
          },
          {
            "label": "Pinecone Metadata Filter",
            "name": "pineconeMetadataFilter",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "acceptVariable": true,
            "id": "pinecone_0-input-pineconeMetadataFilter-json",
            "display": true
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-topK-number",
            "display": true
          },
          {
            "label": "Search Type",
            "name": "searchType",
            "type": "options",
            "default": "similarity",
            "options": [
              {
                "label": "Similarity",
                "name": "similarity"
              },
              {
                "label": "Max Marginal Relevance",
                "name": "mmr"
              }
            ],
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-searchType-options",
            "display": true
          },
          {
            "label": "Fetch K (for MMR Search)",
            "name": "fetchK",
            "description": "Number of initial documents to fetch for MMR reranking. Default to 20. Used only when the search type is MMR",
            "placeholder": "20",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-fetchK-number",
            "display": true
          },
          {
            "label": "Lambda (for MMR Search)",
            "name": "lambda",
            "description": "Number between 0 and 1 that determines the degree of diversity among the results, where 0 corresponds to maximum diversity and 1 to minimum diversity. Used only when the search type is MMR",
            "placeholder": "0.5",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "pinecone_0-input-lambda-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "pinecone_0-input-document-Document",
            "display": true
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "pinecone_0-input-embeddings-Embeddings",
            "display": true
          },
          {
            "label": "Record Manager",
            "name": "recordManager",
            "type": "RecordManager",
            "description": "Keep track of the record to prevent duplication",
            "optional": true,
            "id": "pinecone_0-input-recordManager-RecordManager",
            "display": true
          }
        ],
        "inputs": {
          "document": [
            "{{pdfFile_1.data.instance}}"
          ],
          "embeddings": "{{huggingFaceInferenceEmbeddings_0.data.instance}}",
          "recordManager": "",
          "pineconeIndex": "divno-chatbot",
          "pineconeNamespace": "",
          "fileUpload": "",
          "pineconeTextKey": "",
          "pineconeMetadataFilter": "",
          "topK": "",
          "searchType": "similarity",
          "fetchK": "",
          "lambda": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Pinecone Retriever",
                "description": "",
                "type": "Pinecone | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "pinecone_0-output-vectorStore-Pinecone|VectorStore",
                "name": "vectorStore",
                "label": "Pinecone Vector Store",
                "description": "",
                "type": "Pinecone | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 612,
      "selected": false,
      "positionAbsolute": {
        "x": 1548.5940742991306,
        "y": 277.9050270774794
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 1211.2043214668877,
        "y": 1115.3546185260598
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3.1,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number",
            "display": true
          },
          {
            "label": "Safety Settings",
            "name": "safetySettings",
            "type": "array",
            "description": "Safety settings for the model. Refer to the <a href=\"https://ai.google.dev/gemini-api/docs/safety-settings\">official guide</a> on how to use Safety Settings",
            "array": [
              {
                "label": "Harm Category",
                "name": "harmCategory",
                "type": "options",
                "options": [
                  {
                    "label": "Dangerous",
                    "name": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "description": "Promotes, facilitates, or encourages harmful acts."
                  },
                  {
                    "label": "Harassment",
                    "name": "HARM_CATEGORY_HARASSMENT",
                    "description": "Negative or harmful comments targeting identity and/or protected attributes."
                  },
                  {
                    "label": "Hate Speech",
                    "name": "HARM_CATEGORY_HATE_SPEECH",
                    "description": "Content that is rude, disrespectful, or profane."
                  },
                  {
                    "label": "Sexually Explicit",
                    "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "description": "Contains references to sexual acts or other lewd content."
                  },
                  {
                    "label": "Civic Integrity",
                    "name": "HARM_CATEGORY_CIVIC_INTEGRITY",
                    "description": "Election-related queries."
                  }
                ]
              },
              {
                "label": "Harm Block Threshold",
                "name": "harmBlockThreshold",
                "type": "options",
                "options": [
                  {
                    "label": "None",
                    "name": "BLOCK_NONE",
                    "description": "Always show regardless of probability of unsafe content"
                  },
                  {
                    "label": "Only High",
                    "name": "BLOCK_ONLY_HIGH",
                    "description": "Block when high probability of unsafe content"
                  },
                  {
                    "label": "Medium and Above",
                    "name": "BLOCK_MEDIUM_AND_ABOVE",
                    "description": "Block when medium or high probability of unsafe content"
                  },
                  {
                    "label": "Low and Above",
                    "name": "BLOCK_LOW_AND_ABOVE",
                    "description": "Block when low, medium or high probability of unsafe content"
                  },
                  {
                    "label": "Threshold Unspecified (Default Threshold)",
                    "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED",
                    "description": "Threshold is unspecified, block using default threshold"
                  }
                ]
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-safetySettings-array",
            "display": true
          },
          {
            "label": "Thinking Budget",
            "name": "thinkingBudget",
            "type": "number",
            "description": "Guides the number of thinking tokens. -1 for dynamic, 0 to disable, or positive integer (Gemini 2.5 models).",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "show": {
              "modelName": [
                "gemini-2.5-pro",
                "gemini-2.5-flash",
                "gemini-2.5-flash-lite"
              ]
            },
            "id": "chatGoogleGenerativeAI_0-input-thinkingBudget-number",
            "display": false
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gemini-3-flash-preview",
          "customModelName": "",
          "temperature": 0.9,
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "safetySettings": "",
          "thinkingBudget": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": 1211.2043214668877,
        "y": 1115.3546185260598
      },
      "dragging": false
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 1979.3298963191605,
        "y": 713.8936882868944
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean",
            "display": true
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string",
            "display": true
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "vectorStoreRetriever": "{{pinecone_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": "",
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 538,
      "selected": false,
      "positionAbsolute": {
        "x": 1979.3298963191605,
        "y": 713.8936882868944
      },
      "dragging": false
    },
    {
      "id": "SQLiteRecordManager_0",
      "position": {
        "x": 1954.1516075256031,
        "y": 1405.046212616569
      },
      "type": "customNode",
      "data": {
        "id": "SQLiteRecordManager_0",
        "label": "SQLite Record Manager",
        "version": 1.1,
        "name": "SQLiteRecordManager",
        "type": "SQLite RecordManager",
        "baseClasses": [
          "SQLite RecordManager",
          "RecordManager"
        ],
        "category": "Record Manager",
        "description": "Use SQLite to keep track of document writes into the vector databases",
        "inputParams": [
          {
            "label": "Additional Connection Configuration",
            "name": "additionalConfig",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "SQLiteRecordManager_0-input-additionalConfig-json",
            "display": true
          },
          {
            "label": "Table Name",
            "name": "tableName",
            "type": "string",
            "placeholder": "upsertion_records",
            "additionalParams": true,
            "optional": true,
            "id": "SQLiteRecordManager_0-input-tableName-string",
            "display": true
          },
          {
            "label": "Namespace",
            "name": "namespace",
            "type": "string",
            "additionalParams": true,
            "optional": true,
            "id": "SQLiteRecordManager_0-input-namespace-string",
            "display": true
          },
          {
            "label": "Cleanup",
            "name": "cleanup",
            "type": "options",
            "description": "Read more on the difference between different cleanup methods <a target=\"_blank\" href=\"https://js.langchain.com/docs/modules/data_connection/indexing/#deletion-modes\">here</a>",
            "options": [
              {
                "label": "None",
                "name": "none",
                "description": "No clean up of old content"
              },
              {
                "label": "Incremental",
                "name": "incremental",
                "description": "Delete previous versions of the content if content of the source document has changed. Important!! SourceId Key must be specified and document metadata must contains the specified key"
              },
              {
                "label": "Full",
                "name": "full",
                "description": "Same as incremental, but if the source document has been deleted, it will be deleted from vector store as well, incremental mode will not."
              }
            ],
            "additionalParams": true,
            "default": "none",
            "id": "SQLiteRecordManager_0-input-cleanup-options",
            "display": true
          },
          {
            "label": "SourceId Key",
            "name": "sourceIdKey",
            "type": "string",
            "description": "Key used to get the true source of document, to be compared against the record. Document metadata must contains SourceId Key",
            "default": "source",
            "placeholder": "source",
            "additionalParams": true,
            "optional": true,
            "id": "SQLiteRecordManager_0-input-sourceIdKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "additionalConfig": "",
          "tableName": "",
          "namespace": "",
          "cleanup": "none",
          "sourceIdKey": "source"
        },
        "outputAnchors": [
          {
            "id": "SQLiteRecordManager_0-output-SQLiteRecordManager-SQLite RecordManager|RecordManager",
            "name": "SQLiteRecordManager",
            "label": "SQLite RecordManager",
            "description": "Use SQLite to keep track of document writes into the vector databases",
            "type": "SQLite RecordManager | RecordManager"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 259,
      "selected": false,
      "positionAbsolute": {
        "x": 1954.1516075256031,
        "y": 1405.046212616569
      },
      "dragging": false
    },
    {
      "id": "huggingFaceInferenceEmbeddings_0",
      "position": {
        "x": 444.55403135710907,
        "y": 1178.7816976676875
      },
      "type": "customNode",
      "data": {
        "id": "huggingFaceInferenceEmbeddings_0",
        "label": "HuggingFace Inference Embeddings",
        "version": 1,
        "name": "huggingFaceInferenceEmbeddings",
        "type": "HuggingFaceInferenceEmbeddings",
        "baseClasses": [
          "HuggingFaceInferenceEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "HuggingFace Inference API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "huggingFaceApi"
            ],
            "id": "huggingFaceInferenceEmbeddings_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model",
            "name": "modelName",
            "type": "string",
            "description": "If using own inference endpoint, leave this blank",
            "placeholder": "sentence-transformers/distilbert-base-nli-mean-tokens",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-modelName-string",
            "display": true
          },
          {
            "label": "Endpoint",
            "name": "endpoint",
            "type": "string",
            "placeholder": "https://xyz.eu-west-1.aws.endpoints.huggingface.cloud/sentence-transformers/all-MiniLM-L6-v2",
            "description": "Using your own inference endpoint",
            "optional": true,
            "id": "huggingFaceInferenceEmbeddings_0-input-endpoint-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
          "endpoint": ""
        },
        "outputAnchors": [
          {
            "id": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
            "name": "huggingFaceInferenceEmbeddings",
            "label": "HuggingFaceInferenceEmbeddings",
            "description": "HuggingFace Inference API to generate embeddings for a given text",
            "type": "HuggingFaceInferenceEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 480,
      "positionAbsolute": {
        "x": 444.55403135710907,
        "y": 1178.7816976676875
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "pdfFile_1",
      "position": {
        "x": 713.1579444628917,
        "y": 285.6689724446038
      },
      "type": "customNode",
      "data": {
        "id": "pdfFile_1",
        "label": "Pdf File",
        "version": 2,
        "name": "pdfFile",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from PDF files",
        "inputParams": [
          {
            "label": "Pdf File",
            "name": "pdfFile",
            "type": "file",
            "fileType": ".pdf",
            "id": "pdfFile_1-input-pdfFile-file",
            "display": true
          },
          {
            "label": "Usage",
            "name": "usage",
            "type": "options",
            "options": [
              {
                "label": "One document per page",
                "name": "perPage"
              },
              {
                "label": "One document per file",
                "name": "perFile"
              }
            ],
            "default": "perPage",
            "id": "pdfFile_1-input-usage-options",
            "display": true
          },
          {
            "label": "Use Legacy Build",
            "name": "legacyBuild",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_1-input-legacyBuild-boolean",
            "display": true
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_1-input-metadata-json",
            "display": true
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "pdfFile_1-input-omitMetadataKeys-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "pdfFile_1-input-textSplitter-TextSplitter",
            "display": true
          }
        ],
        "inputs": {
          "textSplitter": "{{recursiveCharacterTextSplitter_0.data.instance}}",
          "usage": "perFile",
          "legacyBuild": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "pdfFile_1-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "pdfFile_1-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 541,
      "positionAbsolute": {
        "x": 713.1579444628917,
        "y": 285.6689724446038
      },
      "selected": false,
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "pinecone_0",
      "sourceHandle": "pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "pinecone_0-pinecone_0-output-retriever-Pinecone|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "huggingFaceInferenceEmbeddings_0",
      "sourceHandle": "huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings",
      "target": "pinecone_0",
      "targetHandle": "pinecone_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "huggingFaceInferenceEmbeddings_0-huggingFaceInferenceEmbeddings_0-output-huggingFaceInferenceEmbeddings-HuggingFaceInferenceEmbeddings|Embeddings-pinecone_0-pinecone_0-input-embeddings-Embeddings"
    },
    {
      "source": "recursiveCharacterTextSplitter_0",
      "sourceHandle": "recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "pdfFile_1",
      "targetHandle": "pdfFile_1-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "recursiveCharacterTextSplitter_0-recursiveCharacterTextSplitter_0-output-recursiveCharacterTextSplitter-RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-pdfFile_1-pdfFile_1-input-textSplitter-TextSplitter"
    },
    {
      "source": "pdfFile_1",
      "sourceHandle": "pdfFile_1-output-document-Document|json",
      "target": "pinecone_0",
      "targetHandle": "pinecone_0-input-document-Document",
      "type": "buttonedge",
      "id": "pdfFile_1-pdfFile_1-output-document-Document|json-pinecone_0-pinecone_0-input-document-Document"
    }
  ]
}